# Infrastructure for a service
This is example terraform infrastructure for hosting simple service running on AWS ECS under single VPC. With bigger scale EKS cluster should be considered. For network separation - public and private subnets have been choosen. Also private subnets will access internet through NAT GW. ECS container will expose given port at private subnets. Access to private subnets will be possible from public subnets. Public subnets, as name suggest will be exposed to outside world using IGW. For bigger scale network separatiuon over multiple VPCs should be cosnidered. LoadBalancer deployed over public subnets have been used as an ingress resources. Access through it is currently limitted over security group only. LoadBalancer have target group and listener configured to route traffic towards private subnets where ECS container is running.
## File structure
Repository file structure is shown below:

![Alt text](images/file_structure.png?raw=true "File structure")

Where "docker" contain Dockerfile for nginx demo hello-world base image. This image should be build and pushed to AWS ECR private image registry. Private registry and base image have been added to easily maintain base functionalities for any future releases.
"live" directory holds infrastructure deployments using modules defined in "modules". This directory holds infrastructure deployment for every environments - "prod" and "test" in this example. Every environment contain infrastructure definitions for different AWS regions. Global resources like IAM, which are not dependent on regions, should be put inside e.g. "global" directory, adjacent to region directories. Going deeper - every region have separate infrastructure deployment definition, some of which could contain additional config files in "configs" folders.
"modules" directory holds definitions of terraform modules, divided by terraform provider - only "aws" have been used for purpose of this POC.

#### Additional notes
This solution haven't been tested and deployed at existing AWS account(s). It's purpose is to present inrastructure code structure and examples. As for the state file handling - s3 bucket can be used in tandem with dynamodb table used for state locking during plan or apply. Mock values have been used as an inputs. Dependencies as outputs in "live" can be used (e.g. between alb and vpc modules) by fetching required values from remote state file or by defining separate s3 bucket with outputs only and then by fetching those values. Sensitive values in inputs can be fetched e.g. from tools like hashicorp vault.
